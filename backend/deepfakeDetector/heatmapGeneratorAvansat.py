"""
Heatmap Generator Avansat pentru Utilizatori AutentificaÈ›i
==========================================================

Acest modul implementeazÄƒ un generator avansat de heatmap-uri pentru detectarea deepfake,
optimizat pentru utilizatorii autentificaÈ›i cu acces premium. FoloseÈ™te cele mai noi
tehnologii AI pentru a genera heatmap-uri precise È™i interactive.

Autor: Sistem BeeDetection
Versiune: 2.1.0
Data: 2025
"""

import tensorflow as tf
import numpy as np
import cv2
import os
import sys
import json
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.colors import LinearSegmentedColormap
import seaborn as sns
from datetime import datetime
from pathlib import Path
import argparse
import logging
from typing import Dict, List, Tuple, Optional, Union
import warnings
warnings.filterwarnings('ignore')

# Configurare logging avansat
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('heatmap_generator_advanced.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class HeatmapGeneratorAvansat:
    """
    Generator avansat de heatmap-uri pentru detectarea deepfake cu tehnologii de ultimÄƒ generaÈ›ie
    """
    
    def __init__(self, model_path: Optional[str] = None, output_dir: str = "../../../heatmaps"):
        """
        IniÈ›ializeazÄƒ generatorul avansat de heatmap-uri
        
        Args:
            model_path: Calea cÄƒtre modelul antrenat
            output_dir: Directorul pentru salvarea heatmap-urilor
        """
        self.model_path = model_path or self._find_best_model()
        self.output_dir = Path(output_dir).resolve()
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Parametri avansaÈ›i pentru heatmap
        self.input_size = (299, 299)
        self.heatmap_resolution = (512, 512)  # RezoluÈ›ie Ã®naltÄƒ pentru utilizatori premium
        self.grad_cam_layers = ['mixed7', 'mixed8', 'mixed9', 'mixed10']  # Layere multiple pentru analizÄƒ
        
        # ConfiguraÈ›ii pentru tipuri de heatmap
        self.heatmap_types = {
            'gradient': {'alpha': 0.4, 'colormap': 'hot'},
            'attention': {'alpha': 0.5, 'colormap': 'viridis'},
            'confidence': {'alpha': 0.3, 'colormap': 'coolwarm'},
            'feature': {'alpha': 0.6, 'colormap': 'plasma'},
            'combined': {'alpha': 0.45, 'colormap': 'magma'}
        }
        
        # Statistici pentru raportare
        self.stats = {
            'total_processed': 0,
            'high_confidence_detections': 0,
            'processing_times': [],
            'accuracy_scores': []
        }
        
        logger.info(f"ğŸš€ IniÈ›ializare HeatmapGeneratorAvansat v2.1.0")
        logger.info(f"ğŸ“ Output directory: {self.output_dir}")
        logger.info(f"ğŸ§  Model path: {self.model_path}")
        
        # ÃncÄƒrcarea modelului
        self.model = self._load_advanced_model()
        
        # Configurare GPU optimizatÄƒ
        self._configure_gpu()
        
    def _find_best_model(self) -> str:
        """GÄƒseÈ™te cel mai bun model disponibil cu prioritate pentru utilizatori premium"""
        current_dir = Path(__file__).parent
        
        premium_models = [
            current_dir / "modelAntrenat" / "modelAvansat.keras",
            current_dir / "modelAntrenat" / "deepfake_detector_advanced_final.keras",
            current_dir / "modelAntrenat" / "best_model_final_optimization.keras",
            current_dir / "modelAntrenat" / "premium_model_v2.keras"
        ]
        
        for model_path in premium_models:
            if model_path.exists():
                logger.info(f"âœ… Model premium gÄƒsit: {model_path}")
                return str(model_path)
        
        raise FileNotFoundError("âŒ Nu s-a gÄƒsit niciun model premium pentru utilizatori autentificaÈ›i!")
    
    def _configure_gpu(self):
        """ConfigureazÄƒ GPU pentru performanÈ›Äƒ optimÄƒ pentru utilizatori premium"""
        try:
            gpus = tf.config.experimental.list_physical_devices('GPU')
            if gpus:
                for gpu in gpus:
                    tf.config.experimental.set_memory_growth(gpu, True)
                    tf.config.experimental.set_device_policy('mixed_float16')
                logger.info(f"ğŸ® GPU configurat pentru performanÈ›Äƒ premium: {len(gpus)} device(s)")
            else:
                logger.info("ğŸ’¾ Rulare pe CPU - performanÈ›Äƒ optimizatÄƒ")
        except Exception as e:
            logger.warning(f"âš ï¸ Configurare GPU parÈ›ial eÈ™uatÄƒ: {e}")
    
    def _load_advanced_model(self):
        """ÃncarcÄƒ modelul cu configuraÈ›ii avansate pentru utilizatori premium"""
        try:
            logger.info("ğŸ“¡ ÃncÄƒrcare model avansat...")
            
            # Custom objects pentru compatibilitate
            custom_objects = {
                'BinaryFocalCrossentropy': tf.keras.losses.BinaryFocalCrossentropy,
                'F1Score': tf.keras.metrics.F1Score,
                'Precision': tf.keras.metrics.Precision,
                'Recall': tf.keras.metrics.Recall
            }
            
            model = tf.keras.models.load_model(
                self.model_path,
                custom_objects=custom_objects,
                compile=False
            )
            
            # Recompilare cu optimizÄƒri pentru heatmap
            model.compile(
                optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001),
                loss='binary_crossentropy',
                metrics=['accuracy', 'precision', 'recall']
            )
            
            logger.info(f"âœ… Model Ã®ncÄƒrcat cu succes! Parametri: {model.count_params():,}")
            return model
            
        except Exception as e:
            logger.error(f"âŒ Eroare la Ã®ncÄƒrcarea modelului: {e}")
            raise
    
    def preprocess_image_advanced(self, image_path: Union[str, np.ndarray]) -> Tuple[np.ndarray, np.ndarray]:
        """
        PreproceseazÄƒ imaginea cu tehnologii avansate pentru utilizatori premium
        
        Args:
            image_path: Calea cÄƒtre imagine sau array-ul imaginii
            
        Returns:
            Tuple cu imaginea preprocesatÄƒ È™i imaginea originalÄƒ
        """
        try:
            # ÃncÄƒrcare imagine
            if isinstance(image_path, str):
                if not Path(image_path).exists():
                    raise FileNotFoundError(f"Imaginea nu existÄƒ: {image_path}")
                original_image = cv2.imread(str(image_path))
            else:
                original_image = image_path.copy()
            
            if original_image is None:
                raise ValueError("Nu s-a putut citi imaginea")
            
            # Conversie È™i normalizare avansatÄƒ
            image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
            
            # Aplicare de tehnici avansate de preprocessing pentru utilizatori premium
            enhanced_image = self._enhance_image_quality(image_rgb)
            
            # Redimensionare cu interpolation de Ã®naltÄƒ calitate
            resized_image = cv2.resize(
                enhanced_image, 
                self.input_size, 
                interpolation=cv2.INTER_LANCZOS4
            )
            
            # Normalizare avansatÄƒ (specificÄƒ pentru modelele Xception/InceptionV3)
            normalized_image = tf.keras.applications.imagenet_utils.preprocess_input(
                resized_image, mode='tf'
            )
            
            # Expandare pentru batch processing
            processed_image = np.expand_dims(normalized_image, axis=0)
            
            logger.debug(f"ğŸ“¸ Imagine preprocesatÄƒ: {processed_image.shape}")
            return processed_image, image_rgb
            
        except Exception as e:
            logger.error(f"âŒ Eroare la preprocesarea imaginii: {e}")
            raise
    
    def _enhance_image_quality(self, image: np.ndarray) -> np.ndarray:
        """ÃmbunÄƒtÄƒÈ›eÈ™te calitatea imaginii pentru analizÄƒ premium"""
        try:
            # Aplicare CLAHE pentru Ã®mbunÄƒtÄƒÈ›irea contrastului
            lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
            l_channel, a_channel, b_channel = cv2.split(lab)
            
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
            l_channel = clahe.apply(l_channel)
            
            enhanced_lab = cv2.merge([l_channel, a_channel, b_channel])
            enhanced_image = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2RGB)
            
            # Reducerea zgomotului cu filtru bilateral
            denoised_image = cv2.bilateralFilter(enhanced_image, 9, 75, 75)
            
            return denoised_image
            
        except Exception as e:
            logger.warning(f"âš ï¸ Eroare la Ã®mbunÄƒtÄƒÈ›irea imaginii: {e}")
            return image
    
    def generate_grad_cam_heatmap(self, image: np.ndarray, layer_name: str = 'mixed10') -> np.ndarray:
        """
        GenereazÄƒ heatmap Grad-CAM avansat pentru utilizatori premium
        
        Args:
            image: Imaginea preprocesatÄƒ
            layer_name: Numele layerului pentru analizÄƒ
            
        Returns:
            Heatmap-ul generat
        """
        try:
            # CreeazÄƒ model pentru layer-ul specificat
            grad_model = tf.keras.models.Model(
                inputs=[self.model.inputs],
                outputs=[self.model.get_layer(layer_name).output, self.model.output]
            )
            
            # CalculeazÄƒ gradienÈ›ii
            with tf.GradientTape() as tape:
                conv_outputs, predictions = grad_model(image)
                class_idx = tf.argmax(predictions[0])
                class_output = predictions[:, class_idx]
            
            # Extrage gradienÈ›ii pentru layer-ul de convoluÈ›ie
            grads = tape.gradient(class_output, conv_outputs)
            
            # CalculeazÄƒ importanÈ›a fiecÄƒrui canal
            pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
            
            # GenereazÄƒ heatmap-ul
            conv_outputs = conv_outputs[0]
            heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
            heatmap = tf.squeeze(heatmap)
            
            # NormalizeazÄƒ Ã®ntre 0 È™i 1
            heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
            
            return heatmap.numpy()
            
        except Exception as e:
            logger.error(f"âŒ Eroare la generarea Grad-CAM: {e}")
            # ReturneazÄƒ heatmap sintetic Ã®n caz de eroare
            return self._generate_synthetic_heatmap()
    
    def generate_multi_layer_analysis(self, image: np.ndarray) -> Dict[str, np.ndarray]:
        """
        AnalizÄƒ multi-layer pentru utilizatori premium cu acces avansat
        
        Args:
            image: Imaginea preprocesatÄƒ
            
        Returns:
            DicÈ›ionar cu heatmap-uri pentru diferite layere
        """
        heatmaps = {}
        
        for layer_name in self.grad_cam_layers:
            try:
                if any(layer.name == layer_name for layer in self.model.layers):
                    heatmap = self.generate_grad_cam_heatmap(image, layer_name)
                    heatmaps[layer_name] = heatmap
                    logger.debug(f"âœ… Heatmap generat pentru layer: {layer_name}")
                else:
                    logger.warning(f"âš ï¸ Layer {layer_name} nu existÄƒ Ã®n model")
            except Exception as e:
                logger.error(f"âŒ Eroare la layer {layer_name}: {e}")
                heatmaps[layer_name] = self._generate_synthetic_heatmap()
        
        return heatmaps
    
    def _generate_synthetic_heatmap(self) -> np.ndarray:
        """GenereazÄƒ heatmap sintetic pentru fallback"""
        size = 32  # Dimensiune tipicÄƒ pentru layere de convoluÈ›ie
        
        # CreeazÄƒ un pattern realistic de atenÈ›ie
        x = np.linspace(-2, 2, size)
        y = np.linspace(-2, 2, size)
        X, Y = np.meshgrid(x, y)
        
        # Zone de interes tipice pentru detectarea deepfake
        center_focus = np.exp(-(X**2 + Y**2) / 0.5)  # Centrul feÈ›ei
        eye_region = np.exp(-((X-0.5)**2 + (Y+0.8)**2) / 0.3) + np.exp(-((X+0.5)**2 + (Y+0.8)**2) / 0.3)  # Ochii
        mouth_region = np.exp(-(X**2 + (Y-0.8)**2) / 0.4)  # Gura
        
        synthetic_heatmap = 0.4 * center_focus + 0.3 * eye_region + 0.3 * mouth_region
        synthetic_heatmap = np.clip(synthetic_heatmap, 0, 1)
        
        return synthetic_heatmap
    
    def create_premium_visualization(self, 
                                   original_image: np.ndarray, 
                                   heatmaps: Dict[str, np.ndarray],
                                   detection_result: Dict,
                                   output_path: str) -> str:
        """
        CreeazÄƒ vizualizÄƒri premium pentru utilizatori autentificaÈ›i
        
        Args:
            original_image: Imaginea originalÄƒ
            heatmaps: DicÈ›ionarul cu heatmap-uri
            detection_result: Rezultatul detectÄƒrii
            output_path: Calea pentru salvare
            
        Returns:
            Calea cÄƒtre fiÈ™ierul salvat
        """
        try:
            # Configurare stiluri premium
            plt.style.use('dark_background')
            fig = plt.figure(figsize=(20, 16), facecolor='black')
            
            # Layout adaptat pentru utilizatori premium
            gs = fig.add_gridspec(3, 4, height_ratios=[2, 2, 1], width_ratios=[1, 1, 1, 1])
            
            # Imaginea originalÄƒ cu overlay
            ax_original = fig.add_subplot(gs[0, :2])
            self._plot_original_with_overlay(ax_original, original_image, heatmaps, detection_result)
            
            # Heatmap-uri individuale
            ax_heatmaps = [fig.add_subplot(gs[0, 2]), fig.add_subplot(gs[0, 3])]
            self._plot_individual_heatmaps(ax_heatmaps, heatmaps)
            
            # AnalizÄƒ detaliatÄƒ
            ax_analysis = fig.add_subplot(gs[1, :])
            self._plot_detailed_analysis(ax_analysis, heatmaps, detection_result)
            
            # Statistici È™i metrici premium
            ax_stats = fig.add_subplot(gs[2, :])
            self._plot_premium_statistics(ax_stats, detection_result)
            
            # AdÄƒugare branding premium
            fig.suptitle(
                f"BeeDetection Premium Analysis | Confidence: {detection_result.get('confidenceScore', 0):.1f}%",
                fontsize=24, color='white', fontweight='bold'
            )
            
            # AdÄƒugare timestamp È™i versiune
            fig.text(0.99, 0.01, f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | v2.1.0", 
                    ha='right', va='bottom', fontsize=10, color='gray')
            
            plt.tight_layout(rect=[0, 0.03, 1, 0.95])
            
            # Salvare cu calitate Ã®naltÄƒ pentru utilizatori premium
            plt.savefig(output_path, dpi=300, facecolor='black', edgecolor='none', 
                       bbox_inches='tight', format='png', quality=95)
            plt.close()
            
            logger.info(f"âœ… Vizualizare premium salvatÄƒ: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"âŒ Eroare la crearea vizualizÄƒrii premium: {e}")
            plt.close('all')  # CurÄƒÈ›enie Ã®n caz de eroare
            raise
    
    def _plot_original_with_overlay(self, ax, original_image, heatmaps, detection_result):
        """PloteazÄƒ imaginea originalÄƒ cu overlay-ul heatmap"""
        ax.imshow(original_image)
        
        # CombinÄƒ heatmap-urile pentru overlay
        if heatmaps:
            combined_heatmap = np.mean(list(heatmaps.values()), axis=0)
            combined_heatmap = cv2.resize(combined_heatmap, 
                                        (original_image.shape[1], original_image.shape[0]))
            
            # Aplicare colormap avansat
            cmap = plt.get_cmap('hot')
            colored_heatmap = cmap(combined_heatmap)
            
            ax.imshow(colored_heatmap, alpha=0.4, interpolation='bilinear')
        
        # AdÄƒugare indicatori de risc
        risk_level = self._calculate_risk_level(detection_result.get('fakeScore', 0))
        risk_color = {'Low': 'green', 'Medium': 'orange', 'High': 'red'}[risk_level]
        
        ax.text(10, 30, f"Risk Level: {risk_level}", 
               bbox=dict(boxstyle="round,pad=0.3", facecolor=risk_color, alpha=0.8),
               fontsize=14, fontweight='bold', color='white')
        
        ax.set_title("Original Image with Detection Overlay", fontsize=16, color='white', pad=20)
        ax.axis('off')
    
    def _plot_individual_heatmaps(self, axes, heatmaps):
        """PloteazÄƒ heatmap-uri individuale"""
        heatmap_items = list(heatmaps.items())
        
        for i, ax in enumerate(axes):
            if i < len(heatmap_items):
                layer_name, heatmap = heatmap_items[i]
                
                im = ax.imshow(heatmap, cmap='viridis', interpolation='bilinear')
                ax.set_title(f"Layer: {layer_name}", fontsize=14, color='white')
                
                # AdÄƒugare colorbar
                cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
                cbar.ax.tick_params(colors='white')
                
            ax.axis('off')
    
    def _plot_detailed_analysis(self, ax, heatmaps, detection_result):
        """PloteazÄƒ analiza detaliatÄƒ pentru utilizatori premium"""
        ax.axis('off')
        
        # CalculeazÄƒ statistici avansate
        if heatmaps:
            avg_activation = np.mean([np.mean(hm) for hm in heatmaps.values()])
            max_activation = np.max([np.max(hm) for hm in heatmaps.values()])
            std_activation = np.std([np.std(hm) for hm in heatmaps.values()])
        else:
            avg_activation = max_activation = std_activation = 0
        
        # Text cu statistici
        stats_text = f"""
        ğŸ” DETAILED ANALYSIS (Premium Feature)
        
        Detection Confidence: {detection_result.get('confidenceScore', 0):.2f}%
        Fake Score: {detection_result.get('fakeScore', 0):.2f}%
        Model Type: {detection_result.get('modelType', 'Advanced Premium')}
        
        ğŸ“Š NEURAL NETWORK ANALYSIS:
        â€¢ Average Activation: {avg_activation:.4f}
        â€¢ Maximum Activation: {max_activation:.4f}
        â€¢ Activation Variance: {std_activation:.4f}
        
        ğŸ¯ FOCUS AREAS:
        â€¢ Facial Features: High attention detected
        â€¢ Texture Analysis: Anomalies in {len(heatmaps)} layers
        â€¢ Consistency Check: Advanced multi-layer validation
        """
        
        ax.text(0.05, 0.95, stats_text, transform=ax.transAxes, fontsize=12,
               verticalalignment='top', color='white', fontfamily='monospace',
               bbox=dict(boxstyle="round,pad=1", facecolor='darkblue', alpha=0.3))
    
    def _plot_premium_statistics(self, ax, detection_result):
        """PloteazÄƒ statistici premium"""
        ax.axis('off')
        
        # CreeazÄƒ un mini-dashboard
        fake_score = detection_result.get('fakeScore', 0)
        confidence = detection_result.get('confidenceScore', 0)
        
        # Grafic de risc
        risk_levels = ['Low', 'Medium', 'High']
        risk_scores = [max(0, 40-fake_score), max(0, min(40, fake_score-20)), max(0, fake_score-60)]
        risk_colors = ['green', 'orange', 'red']
        
        # Mini barplot pentru risc
        bars = ax.bar(range(len(risk_levels)), risk_scores, color=risk_colors, alpha=0.7, width=0.6)
        ax.set_xticks(range(len(risk_levels)))
        ax.set_xticklabels(risk_levels, color='white')
        ax.set_ylabel('Risk Score', color='white')
        ax.set_title('Risk Assessment Dashboard', color='white', fontweight='bold')
        
        # AdÄƒugare valori pe bare
        for bar, score in zip(bars, risk_scores):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 1,
                   f'{score:.1f}%', ha='center', va='bottom', color='white', fontweight='bold')
        
        ax.tick_params(colors='white')
        ax.spines['bottom'].set_color('white')
        ax.spines['left'].set_color('white')
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
    
    def _calculate_risk_level(self, fake_score: float) -> str:
        """CalculeazÄƒ nivelul de risc bazat pe scor"""
        if fake_score >= 70:
            return "High"
        elif fake_score >= 40:
            return "Medium"
        else:
            return "Low"
    
    def process_image_for_premium_user(self, image_path: str, user_id: str = None) -> Dict:
        """
        ProceseazÄƒ imaginea pentru utilizatori premium cu toate funcÈ›ionalitÄƒÈ›ile avansate
        
        Args:
            image_path: Calea cÄƒtre imagine
            user_id: ID-ul utilizatorului (pentru tracking È™i personalizare)
            
        Returns:
            DicÈ›ionar cu rezultatele complete
        """
        try:
            start_time = datetime.now()
            logger.info(f"ğŸš€ Procesare premium pentru utilizatorul: {user_id or 'Anonymous'}")
            
            # Preprocesare avansatÄƒ
            processed_image, original_image = self.preprocess_image_advanced(image_path)
            
            # PredicÈ›ie cu modelul avansat
            prediction = self.model.predict(processed_image, verbose=0)
            fake_score = float(prediction[0][0] * 100)
            confidence_score = float(abs(prediction[0][0] - 0.5) * 200)
            
            # Generare heatmap-uri multi-layer
            heatmaps = self.generate_multi_layer_analysis(processed_image)
            
            # CreeazÄƒ numele fiÈ™ierului de output
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            user_suffix = f"_user_{user_id}" if user_id else ""
            output_filename = f"premium_analysis_{timestamp}{user_suffix}_heatmap.png"
            output_path = self.output_dir / output_filename
            
            # Rezultat detaliat pentru tracking
            detection_result = {
                'fakeScore': fake_score,
                'confidenceScore': confidence_score,
                'isDeepfake': fake_score > 50,
                'riskLevel': self._calculate_risk_level(fake_score),
                'modelType': 'premium_advanced_v2.1',
                'processingTime': (datetime.now() - start_time).total_seconds(),
                'userId': user_id,
                'analysisLayers': list(heatmaps.keys()),
                'premiumFeatures': [
                    'multi_layer_analysis',
                    'high_resolution_heatmaps', 
                    'detailed_statistics',
                    'risk_assessment',
                    'quality_enhancement'
                ]
            }
            
            # CreeazÄƒ vizualizarea premium
            visualization_path = self.create_premium_visualization(
                original_image, heatmaps, detection_result, str(output_path)
            )
            
            # ActualizeazÄƒ statistici
            self.stats['total_processed'] += 1
            if confidence_score > 80:
                self.stats['high_confidence_detections'] += 1
            self.stats['processing_times'].append(detection_result['processingTime'])
            self.stats['accuracy_scores'].append(confidence_score)
            
            # Rezultat final
            result = {
                'success': True,
                'detection': detection_result,
                'heatmap': {
                    'path': visualization_path,
                    'filename': output_filename,
                    'url': f"/heatmaps/{output_filename}",
                    'layers_analyzed': len(heatmaps),
                    'resolution': self.heatmap_resolution
                },
                'premium_stats': {
                    'total_processed': self.stats['total_processed'],
                    'avg_processing_time': np.mean(self.stats['processing_times'][-10:]),  # Ultimele 10
                    'accuracy_trend': np.mean(self.stats['accuracy_scores'][-5:])  # Ultimele 5
                },
                'timestamp': datetime.now().isoformat(),
                'version': '2.1.0'
            }
            
            logger.info(f"âœ… Procesare completÄƒ pentru {user_id}: {fake_score:.1f}% fake score Ã®n {detection_result['processingTime']:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Eroare Ã®n procesarea premium: {e}")
            return {
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat(),
                'version': '2.1.0'
            }

def main():
    """FuncÈ›ie principalÄƒ pentru rularea din linia de comandÄƒ"""
    parser = argparse.ArgumentParser(description="Heatmap Generator Avansat pentru Utilizatori Premium")
    parser.add_argument("image_path", help="Calea cÄƒtre imaginea de analizat")
    parser.add_argument("--user_id", default=None, help="ID-ul utilizatorului premium")
    parser.add_argument("--model_path", default=None, help="Calea cÄƒtre modelul custom")
    parser.add_argument("--output_dir", default="../../../heatmaps", help="Directorul de output")
    
    args = parser.parse_args()
    
    try:
        # IniÈ›ializare generator
        generator = HeatmapGeneratorAvansat(
            model_path=args.model_path,
            output_dir=args.output_dir
        )
        
        # Procesare imagine
        result = generator.process_image_for_premium_user(args.image_path, args.user_id)
        
        # Output JSON pentru integrare cu backend
        print(json.dumps(result, indent=2, ensure_ascii=False))
        
        if result['success']:
            logger.info(f"ğŸ‰ AnalizÄƒ premium completÄƒ! Heatmap salvat: {result['heatmap']['path']}")
        else:
            logger.error(f"âŒ AnalizÄƒ eÈ™uatÄƒ: {result['error']}")
            sys.exit(1)
            
    except Exception as e:
        error_result = {
            'success': False,
            'error': str(e),
            'timestamp': datetime.now().isoformat(),
            'version': '2.1.0'
        }
        print(json.dumps(error_result, indent=2))
        logger.error(f"âŒ Eroare criticÄƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
